{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "# The Gemini 1.5 models are versatile and work with both text-only and multimodal prompts\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = r\"C:\\Users\\hoang\\OneDrive\\Desktop\\nghich_prj\\Hackathon\\Hack-CMC-Heineken\\data\\FULL [Heineken Vietnam] Developer Resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_VI = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_EN = \"\"\"\n",
    "You are given an image related to Heineken beer products and various activities to enhance their service quality in customer experience.\n",
    "The images may depict grocery stores with Heineken products, street activities by Heineken staff, bars, pubs, restaurants, special events like gameshows, and more.\n",
    "Analyze each image and provide the following information:\n",
    "\n",
    "- context: The place context in the image. For examples: bar, restaurant, grocery store, supermarket, small pub,... Just return me the place, not explain or say any un need words\n",
    "- activity: list of short keyword describe human activities happend in image\n",
    "- emotion: list of the main emotion of people in the image \n",
    "- effectiveness: If there are activities to enhance the user experience for example event, enjoy product..., i want to know how success, efficiency it be or whether it need to be improved, how to improve in short\n",
    "\n",
    "Ensure the values are short, informative, and useful for further statistical analysis. If any of the criteria do not apply to the image, return null for that key.\n",
    "Format the response in JSON\n",
    "\n",
    "**Example response:**\n",
    "{\n",
    "  \"context\": \"bar\"\n",
    "  \"activity\": [\"drinking\", \"eating\"],\n",
    "  \"emotion\": [\"happy\", \"enjoyable\"],\n",
    "  \"effectiveness\": null,\n",
    "}\n",
    "{\n",
    "  \"context\": \"street\"\n",
    "  \"activity\": [\"beer promotion\", \"play game\"],\n",
    "  \"emotion\": [\"happy\", \"interested\"],\n",
    "  \"effectiveness\": \"highly effective\",\n",
    "}\n",
    "{\n",
    "  \"context\": \"grocery store\",\n",
    "  \"activity\": null,\n",
    "  \"emotion\": null,\n",
    "  \"effectiveness\": null\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(img_path):\n",
    "    sample_file = genai.upload_file(path=img_path,\n",
    "                            display_name=\"Image\")\n",
    "\n",
    "    response = model.generate_content([sample_file, PROMPT_EN])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open(\"./response_activities_emo_en.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "    successed = [item['path'] for item in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1484/1484 [11:20:34<00:00, 27.52s/it]       \n"
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "\n",
    "for img_name in tqdm(os.listdir(DATA_URL)):\n",
    "    if img_name in successed:\n",
    "        print(\"SKIP\")\n",
    "        continue\n",
    "    try:\n",
    "        fpath = os.path.join(DATA_URL, img_name)\n",
    "        response  = get_response(fpath)\n",
    "        results.append({\n",
    "            \"path\": img_name,\n",
    "            \"response\": response\n",
    "        })\n",
    "        with open(\"./response_activities_emo_en.json\", \"w\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        failed.append({\n",
    "            \"path\": img_name,\n",
    "            \"reason\": str(e)\n",
    "        })\n",
    "        with open(\"./failed.json\", \"w\") as f:\n",
    "            json.dump(failed, f, ensure_ascii=False, indent=2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
